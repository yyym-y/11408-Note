# 一、Cache 写策略


## 2. 本节总览

本节主要探讨在 CPU 进行**写操作**时，Cache 如何与主存协作以维护数据一致性。需要注意的是，**只有写操作才会导致数据不一致问题，读操作则不会。**

我们将从两个维度来讨论写策略：

* **写命中 (Write Hit) 情况：** 当 CPU 要写入的数据块已经在 Cache 中时，如何处理？
    * **写回法 (Write Back)**
    * **全写法 (Write Through)**
* **写不命中 (Write Miss) 情况：** 当 CPU 要写入的数据块不在 Cache 中时，如何处理？
    * **写分配法 (Write Allocate)**
    * **非写分配法 (No-Write Allocate)**

---

## 3. 写命中

当 CPU 要写入的数据块已经在 Cache 中时，有两种主要的策略来处理。

### 3.1 写回法 (Write Back)

**工作原理：**

* 当 CPU 执行写操作且命中了 Cache 时，**只修改 Cache 中的数据副本**，而**不立即写入主存**。
* 主存中的数据会在未来某个时刻才被更新。这个“未来时刻”通常是当该 Cache 行被**替换（淘汰）出 Cache** 时，才将其写回主存。

**实现机制：**

* 为了实现写回法，每个 Cache 行都需要额外增加一个 **“脏位 (Dirty Bit)”**（或称修改位/M 位）。
* 当 Cache 行中的数据被 CPU 修改时，该行的脏位被置为 **1**。
* 当 Cache 行要被替换出去时，系统会检查其脏位：
    * 如果脏位为 **1**，表示该行已被修改且与主存不一致，必须将该行的数据**写回主存**，然后才能替换。
    * 如果脏位为 **0**，表示该行的数据与主存一致，可以直接**淘汰**（无需写回主存）。

**特点：**

* **减少访存次数：** 由于不是每次写操作都访问主存，显著**减少了写操作对主存的访问次数**。
* **提升写操作速度：** CPU 的写操作大部分在高速的 Cache 中完成，从而**提升了写操作的速度**。
* **存在数据不一致隐患：** 在 Cache 中的数据被修改但尚未写回主存的这段时间内，主存中的数据是旧的、不一致的。这在多核或多总线系统中可能导致问题。
* **适合搭配写分配法使用：** 由于其“延迟写入”的特性，写回法通常与**写分配法**（后面会介绍）配合使用，以充分利用局部性原理。

### 3.2 全写法 (Write Through)

**工作原理：**

* 当 CPU 执行写操作且命中了 Cache 时，**同时将数据写入 Cache 和主存**。
* 这保证了 Cache 和主存中的数据**始终保持一致**（或者说，主存中的数据总是最新的）。

**实现优化：写缓冲 (Write Buffer)**

* 为了避免直接写入主存的慢速影响 CPU 速度，全写法通常会引入一个**写缓冲 (Write Buffer)**。
* 写缓冲是一个由 **SRAM** 实现的 **FIFO（先进先出）队列**。
* CPU 进行写操作时，数据会**同时写入 Cache 和写缓冲**。CPU 立即继续执行其他任务，由**后台控制器**将写缓冲中的数据异步写入主存。

**特点：**

* **保证数据强一致性：** Cache 和主存的数据总是保持同步，避免了不一致问题。
* **写缓冲饱和时 CPU 需等待：** 如果写缓冲的速度跟不上 CPU 写入的速度，写缓冲可能饱和。此时 CPU 必须等待写缓冲有空闲才能继续写操作，导致性能下降。
* **写操作对主存依赖大：** 每次写操作都必须访问主存，即使通过写缓冲优化，理论上访存次数也多于写回法。
* **适合搭配非写分配法使用：** 由于其“实时写入”的特性，全写法通常与**非写分配法**配合使用。

---

## 4. 写不命中

当 CPU 要写入的数据块不在 Cache 中时，有两种主要策略来处理。

### 4.1 写分配法 (Write Allocate)

**处理流程：**

* 当写操作发生未命中时，系统会**首先将目标主存块调入 Cache**（即“分配”一个 Cache 行）。
* 然后，在 Cache 中对该块的数据进行修改。
* 后续对该块的访问就可以命中 Cache 了。

**搭配策略：**

* 写分配法通常与**写回法**配合使用。
* 这意味着，当一个新块被调入 Cache 并被修改后，只有当它被替换出 Cache 时，其修改才会被写回主存。
* 这种组合充分利用了**时间局部性**：如果一个数据块被写入，很可能在短时间内再次被访问（读或写），将其留在 Cache 中可以提高后续访问的命中率。

**适用场景：**

* 适合**局部性较好的访问模式**，尤其是写操作也具有良好局部性的场景。

### 4.2 非写分配法 (No-Write Allocate)

**处理流程：**

* 当写操作发生未命中时，系统**不将目标主存块调入 Cache**。
* 而是**直接将数据写入主存**。

**搭配策略：**

* 非写分配法通常与**全写法**配合使用。
* 这意味着，只有在**读不命中**时，数据块才会被调入 Cache。写不命中时，数据直接绕过 Cache 写入主存。

**适用场景：**

* 适合**随机写入**的场景，因为这些写入操作不具有良好的局部性，调入 Cache 可能会污染 Cache 中的热点数据，反而降低效率。

---

## 5. 多级 Cache

为了进一步优化性能和平衡成本，现代 CPU 通常采用**多级 Cache 结构**。

**层级特点：**

* **L1 Cache：** 最接近 CPU 核心，速度最快（例如，读写速度可达 **1000GB/s** 甚至更高），容量最小（通常几十到几百 KB，如 128KB），通常分为 L1 指令 Cache 和 L1 数据 Cache。延迟极低（例如 1.0ns）。
* **L2 Cache：** 位于 L1 和 L3 之间，速度次之（例如，读写速度约 **400GB/s**），容量比 L1 大（通常几百 KB 到几 MB，如 2MB）。延迟稍高（例如 3.1ns）。
* **L3 Cache：** 通常是片上共享 Cache，速度比 L2 慢（例如，读写速度约 **250GB/s**），容量最大（通常几 MB 到几十 MB）。延迟进一步增加（例如 13.5ns）。
* **主存 (Main Memory)：** 速度最慢（例如，读写速度约 37GB/s），但容量最大（通常几 GB 到几百 GB）。延迟最高（例如 56.1ns）。

**数据同步策略（分层组合）：**

多级 Cache 系统中，各层级之间的数据同步策略也经过精心设计，以达到最佳性能和一致性：

* **各级 Cache 之间（例如 L1 与 L2 之间，L2 与 L3 之间）：**
    * 通常采用**全写法 (Write Through)** + **非写分配法 (No-Write Allocate)**。
    * 原因：确保上层 Cache 的修改立即同步到下层 Cache，保持一致性。非写分配可以避免将不常用的数据块逐级调入上层 Cache。
* **Cache 与主存之间（通常是 L3 Cache 与主存之间）：**
    * 通常采用**写回法 (Write Back)** + **写分配法 (Write Allocate)**。
    * 原因：这是为了降低访存频率，利用写操作的局部性，提升整体性能。只有当 Cache 块被替换时才写回主存，从而减少了慢速主存的访问。


---


## 二、知识小结

| 知识点                 | 核心内容                                                                                                                       | 考试重点/易混淆点                                                                                                                                                                             | 难度系数 |
| :--------------------- | :----------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------- |
| **Cache 写策略** | 解决Cache与主存数据一致性问题，分为命中（写回法、全写法）和未命中（写分配法、非写分配法）两种情况。                                       | **写回法 vs 全写法：** 写回法延迟同步（淘汰时写回），全写法实时同步（需写缓冲优化）。**写分配法 vs 非写分配法：** 写分配法先调入Cache再写，非写分配法直接写主存。              | ⭐⭐⭐     |
| **多级Cache结构** | 层级越接近CPU速度越快（如L1>L2>L3），容量越小。数据同步策略：**各级Cache间用全写法+非写分配法，Cache与主存间用写回法+写分配法。** | 多级Cache的读写速度差异（如L1$$\approx$$1000GB/s，L2$$\approx$$500GB/s）。                                                                                                              | ⭐⭐      |
| **Cache映射方式** | 主存与Cache数据块对应关系：全相联映射、直接映射、组相联映射。                                                                                | 组相联映射是前两者的折中方案，需掌握地址划分逻辑。                                                                                                                                            | ⭐⭐⭐⭐    |
| **Cache替换算法** | 淘汰策略：LRU（近期最少使用）、FIFO（先进先出）、随机等。                                                                               | LRU算法的实际实现复杂度（需硬件支持计数器或栈）。                                                                                                                                              | ⭐⭐⭐     |
| **数据一致性隐患** | 写回法存在主存与Cache临时不一致问题，需**脏位**标记；全写法依赖写缓冲可能饱和。                                                               | **脏位的硬件实现与淘汰判断逻辑。** 这是写回法实现的关键。                                                                                                                                     | ⭐⭐⭐⭐    |